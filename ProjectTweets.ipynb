{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac2e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "spark = SparkSession.builder.appName('ProjectTweets').enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf717f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, col, lower\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pyspark.sql.functions import udf\n",
    "from pymongo import MongoClient\n",
    "from pyspark.sql.types import StringType\n",
    "import nltk\n",
    "#nltk.download('omw-1.4')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ffa58",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91573341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('/user1/ProjectTweets.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61bd395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: integer (nullable = true)\n",
      " |-- 1467810369: long (nullable = true)\n",
      " |-- Mon Apr 06 22:19:45 PDT 2009: string (nullable = true)\n",
      " |-- NO_QUERY: string (nullable = true)\n",
      " |-- _TheSpecialOne_: string (nullable = true)\n",
      " |-- @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5363c840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|0  |1467810369|Mon Apr 06 22:19:45 PDT 2009|NO_QUERY|_TheSpecialOne_|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |1467810672|Mon Apr 06 22:19:49 PDT 2009|NO_QUERY|scotthamilton  |is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!    |\n",
      "|2  |1467810917|Mon Apr 06 22:19:53 PDT 2009|NO_QUERY|mattycus       |@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                          |\n",
      "|3  |1467811184|Mon Apr 06 22:19:57 PDT 2009|NO_QUERY|ElleCTF        |my whole body feels itchy and like its on fire                                                                     |\n",
      "|4  |1467811193|Mon Apr 06 22:19:57 PDT 2009|NO_QUERY|Karoli         |@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.     |\n",
      "|5  |1467811372|Mon Apr 06 22:20:00 PDT 2009|NO_QUERY|joy_wolf       |@Kwesidei not the whole crew                                                                                       |\n",
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a60c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c358289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = ['ids', 'date', 'flag', 'user', 'text']\n",
    "\n",
    "for i, column_name in enumerate(new_cols):\n",
    "    df = df.withColumnRenamed(df.columns[i + 1], column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31d1f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb99dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.legacy.timeParserPolicy', 'LEGACY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f77ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_column = df.select('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2baf2eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('date', to_date(df['date'], 'EEE MMM dd HH:mm:ss zzz yyyy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a856b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('date', to_date(col('date'), 'dd/MM/yyyy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06d9721a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------+---------------+--------------------+\n",
      "|  0|       ids|      date|    flag|           user|                text|\n",
      "+---+----------+----------+--------+---------------+--------------------+\n",
      "|  1|1467810672|2009-04-07|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|  2|1467810917|2009-04-07|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|  3|1467811184|2009-04-07|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|  4|1467811193|2009-04-07|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|  5|1467811372|2009-04-07|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|  6|1467811592|2009-04-07|NO_QUERY|        mybirch|         Need a hug |\n",
      "|  7|1467811594|2009-04-07|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|  8|1467811795|2009-04-07|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|  9|1467812025|2009-04-07|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "| 10|1467812416|2009-04-07|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "| 11|1467812579|2009-04-07|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "| 12|1467812723|2009-04-07|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "| 13|1467812771|2009-04-07|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "| 14|1467812784|2009-04-07|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "| 15|1467812799|2009-04-07|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "| 16|1467812964|2009-04-07|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "| 17|1467813137|2009-04-07|NO_QUERY|       armotley|about to file taxes |\n",
      "| 18|1467813579|2009-04-07|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "| 19|1467813782|2009-04-07|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "| 20|1467813985|2009-04-07|NO_QUERY|         quanvu|@alydesigns i was...|\n",
      "+---+----------+----------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28086db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: integer (nullable = true)\n",
      " |-- ids: long (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "572dff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data to lowercase and clean unnecessary characters\n",
    "df = df.withColumn(\"text\", lower(regexp_replace(col(\"text\"), \"[^a-zA-Z0-9\\\\s]\", \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fc3289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special symbols, and links from text data\n",
    "df = df.withColumn(\"text\", regexp_replace(col(\"text\"), r'[@#]\\w+|https?://\\S+|\\W', \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e34447de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------+-------------+---------------------------------------------------------------------------------------------------------------+\n",
      "|0  |ids       |date      |flag    |user         |text                                                                                                           |\n",
      "+---+----------+----------+--------+-------------+---------------------------------------------------------------------------------------------------------------+\n",
      "|1  |1467810672|2009-04-07|NO_QUERY|scotthamilton|is upset that he can t update his facebook by texting it    and might cry as a result  school today also  blah |\n",
      "+---+----------+----------+--------+-------------+---------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cb97431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization using NLTK\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "lemmatize_udf = udf(lemmatize_text, StringType())\n",
    "df = df.withColumn(\"text\", lemmatize_udf(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "595fcaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"filtered_words\")\n",
    "df = tokenizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb950b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------+-------------+--------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0  |ids       |date      |flag    |user         |text                                                                                                    |filtered_words                                                                                                                 |\n",
      "+---+----------+----------+--------+-------------+--------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |1467810672|2009-04-07|NO_QUERY|scotthamilton|is upset that he can t update his facebook by texting it and might cry a a result school today also blah|[is, upset, that, he, can, t, update, his, facebook, by, texting, it, and, might, cry, a, a, result, school, today, also, blah]|\n",
      "+---+----------+----------+--------+-------------+--------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df0794fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use StopWordsRemover on the \"filtered_words\" column in your example DataFrame\n",
    "remover = StopWordsRemover(inputCol=\"filtered_words\", outputCol=\"filtered_words_without_stopwords\")\n",
    "df = remover.transform(df)\n",
    "\n",
    "# You can update the column name as per your needs\n",
    "df = df.withColumnRenamed(\"filtered_words_without_stopwords\", \"filtered_words_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7435bdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+--------+---------------+---------------------------------------------------------------------------------+\n",
      "|tweet_index|ids       |date      |flag    |user           |filtered_words_final                                                             |\n",
      "+-----------+----------+----------+--------+---------------+---------------------------------------------------------------------------------+\n",
      "|1          |1467810672|2009-04-07|NO_QUERY|scotthamilton  |[upset, update, facebook, texting, might, cry, result, school, today, also, blah]|\n",
      "|2          |1467810917|2009-04-07|NO_QUERY|mattycus       |[kenichan, dived, many, time, ball, managed, save, 50, rest, go, bound]          |\n",
      "|3          |1467811184|2009-04-07|NO_QUERY|ElleCTF        |[whole, body, feel, itchy, like, fire]                                           |\n",
      "|4          |1467811193|2009-04-07|NO_QUERY|Karoli         |[nationwideclass, behaving, m, mad, see]                                         |\n",
      "|5          |1467811372|2009-04-07|NO_QUERY|joy_wolf       |[kwesidei, whole, crew]                                                          |\n",
      "|6          |1467811592|2009-04-07|NO_QUERY|mybirch        |[need, hug]                                                                      |\n",
      "|7          |1467811594|2009-04-07|NO_QUERY|coZZ           |[loltrish, hey, long, time, see, yes, rain, bit, bit, lol, m, fine, thanks]      |\n",
      "|8          |1467811795|2009-04-07|NO_QUERY|2Hood4Hollywood|[tatiana, k, nope, didn]                                                         |\n",
      "|9          |1467812025|2009-04-07|NO_QUERY|mimismo        |[twittera, que, muera]                                                           |\n",
      "|10         |1467812416|2009-04-07|NO_QUERY|erinx3leannexo |[spring, break, plain, city, snowing]                                            |\n",
      "|11         |1467812579|2009-04-07|NO_QUERY|pardonlauren   |[re, pierced, ear]                                                               |\n",
      "|12         |1467812723|2009-04-07|NO_QUERY|TLeC           |[caregiving, couldn, bear, watch, thought, ua, loss, wa, embarrassing]           |\n",
      "|13         |1467812771|2009-04-07|NO_QUERY|robrobbierobert|[octolinz16, count, idk, either, never, talk, anymore]                           |\n",
      "|14         |1467812784|2009-04-07|NO_QUERY|bayofwolves    |[smarrison, ve, first, didn, gun, really, though, zac, snyder, doucheclown]      |\n",
      "|15         |1467812799|2009-04-07|NO_QUERY|HairByJess     |[iamjazzyfizzle, wish, got, watch, miss, iamlilnicki, wa, premiere]              |\n",
      "|16         |1467812964|2009-04-07|NO_QUERY|lovesongwriter |[hollis, death, scene, hurt, severely, watch, film, wry, director, cut]          |\n",
      "|17         |1467813137|2009-04-07|NO_QUERY|armotley       |[file, tax]                                                                      |\n",
      "|18         |1467813579|2009-04-07|NO_QUERY|starkissed     |[lettya, ahh, ive, always, wanted, see, rent, love, soundtrack]                  |\n",
      "|19         |1467813782|2009-04-07|NO_QUERY|gi_gi_bee      |[fakerpattypattz, oh, dear, drinking, forgotten, table, drink]                   |\n",
      "|20         |1467813985|2009-04-07|NO_QUERY|quanvu         |[alydesigns, wa, day, didn, get, much, done]                                     |\n",
      "+-----------+----------+----------+--------+---------------+---------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Just pick the necessary columns\n",
    "df = df.select('0', 'ids', 'date', 'flag', 'user', 'filtered_words_final')\n",
    "\n",
    "# Rename the \"0\" column to \"index\"\n",
    "df = df.withColumnRenamed(\"0\", \"tweet_index\")\n",
    "\n",
    "# Show the result\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba62fe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+--------+---------------+--------------------+\n",
      "|tweet_index|       ids|      date|    flag|           user|filtered_words_final|\n",
      "+-----------+----------+----------+--------+---------------+--------------------+\n",
      "|          1|1467810672|2009-04-07|NO_QUERY|  scotthamilton|[upset, update, f...|\n",
      "|          2|1467810917|2009-04-07|NO_QUERY|       mattycus|[kenichan, dived,...|\n",
      "|          3|1467811184|2009-04-07|NO_QUERY|        ElleCTF|[whole, body, fee...|\n",
      "|          4|1467811193|2009-04-07|NO_QUERY|         Karoli|[nationwideclass,...|\n",
      "|          5|1467811372|2009-04-07|NO_QUERY|       joy_wolf|[kwesidei, whole,...|\n",
      "|          6|1467811592|2009-04-07|NO_QUERY|        mybirch|         [need, hug]|\n",
      "|          7|1467811594|2009-04-07|NO_QUERY|           coZZ|[loltrish, hey, l...|\n",
      "|          8|1467811795|2009-04-07|NO_QUERY|2Hood4Hollywood|[tatiana, k, nope...|\n",
      "|          9|1467812025|2009-04-07|NO_QUERY|        mimismo|[twittera, que, m...|\n",
      "|         10|1467812416|2009-04-07|NO_QUERY| erinx3leannexo|[spring, break, p...|\n",
      "|         11|1467812579|2009-04-07|NO_QUERY|   pardonlauren|  [re, pierced, ear]|\n",
      "|         12|1467812723|2009-04-07|NO_QUERY|           TLeC|[caregiving, coul...|\n",
      "|         13|1467812771|2009-04-07|NO_QUERY|robrobbierobert|[octolinz16, coun...|\n",
      "|         14|1467812784|2009-04-07|NO_QUERY|    bayofwolves|[smarrison, ve, f...|\n",
      "|         15|1467812799|2009-04-07|NO_QUERY|     HairByJess|[iamjazzyfizzle, ...|\n",
      "|         16|1467812964|2009-04-07|NO_QUERY| lovesongwriter|[hollis, death, s...|\n",
      "|         17|1467813137|2009-04-07|NO_QUERY|       armotley|         [file, tax]|\n",
      "|         18|1467813579|2009-04-07|NO_QUERY|     starkissed|[lettya, ahh, ive...|\n",
      "|         19|1467813782|2009-04-07|NO_QUERY|      gi_gi_bee|[fakerpattypattz,...|\n",
      "|         20|1467813985|2009-04-07|NO_QUERY|         quanvu|[alydesigns, wa, ...|\n",
      "+-----------+----------+----------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.dropna().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1281d496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of values in the dataframe 1599999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the total number of values in the dataframe\n",
    "total_count = df.count()\n",
    "\n",
    "# Show the total count\n",
    "print(\"Total count of values in the dataframe\", total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79986ea3",
   "metadata": {},
   "source": [
    "# MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd55fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "# Connect to the database\n",
    "connection = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"password\",\n",
    "    database=\"ProjectTweets\",\n",
    "    charset='utf8mb4',\n",
    "    cursorclass=pymysql.cursors.DictCursor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f13a6c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a cursor\n",
    "# cursor = connection.cursor()\n",
    "\n",
    "# # Create a table\n",
    "# create_table_sql = \"\"\"\n",
    "# CREATE TABLE Tweets (\n",
    "#     tweet_index INT AUTO_INCREMENT PRIMARY KEY,\n",
    "#     ids BIGINT,\n",
    "#     date DATE,\n",
    "#     flag VARCHAR(55),\n",
    "#     user VARCHAR(255),\n",
    "#     filtered_words_final TEXT\n",
    "# );\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9ed8b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table\n",
    "#cursor.execute(create_table_sql)\n",
    "\n",
    "# Save changes\n",
    "#connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36c36c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet_index: integer (nullable = true)\n",
      " |-- ids: long (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- filtered_words_final: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70aeee81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet_index: integer (nullable = true)\n",
      " |-- ids: long (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- filtered_words_final: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- concatenated_words: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 'filtered_words_final' adındaki sütunu virgülle ayrılmış bir metin sütunu olarak birleştirin.\n",
    "df = df.withColumn('concatenated_words', concat_ws(\",\", df['filtered_words_final']))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3078f1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+--------+---------------+---------------------------------------------------------------------+\n",
      "|tweet_index|ids       |date      |flag    |user           |concatenated_words                                                   |\n",
      "+-----------+----------+----------+--------+---------------+---------------------------------------------------------------------+\n",
      "|1          |1467810672|2009-04-07|NO_QUERY|scotthamilton  |upset,update,facebook,texting,might,cry,result,school,today,also,blah|\n",
      "|2          |1467810917|2009-04-07|NO_QUERY|mattycus       |kenichan,dived,many,time,ball,managed,save,50,rest,go,bound          |\n",
      "|3          |1467811184|2009-04-07|NO_QUERY|ElleCTF        |whole,body,feel,itchy,like,fire                                      |\n",
      "|4          |1467811193|2009-04-07|NO_QUERY|Karoli         |nationwideclass,behaving,m,mad,see                                   |\n",
      "|5          |1467811372|2009-04-07|NO_QUERY|joy_wolf       |kwesidei,whole,crew                                                  |\n",
      "|6          |1467811592|2009-04-07|NO_QUERY|mybirch        |need,hug                                                             |\n",
      "|7          |1467811594|2009-04-07|NO_QUERY|coZZ           |loltrish,hey,long,time,see,yes,rain,bit,bit,lol,m,fine,thanks        |\n",
      "|8          |1467811795|2009-04-07|NO_QUERY|2Hood4Hollywood|tatiana,k,nope,didn                                                  |\n",
      "|9          |1467812025|2009-04-07|NO_QUERY|mimismo        |twittera,que,muera                                                   |\n",
      "|10         |1467812416|2009-04-07|NO_QUERY|erinx3leannexo |spring,break,plain,city,snowing                                      |\n",
      "|11         |1467812579|2009-04-07|NO_QUERY|pardonlauren   |re,pierced,ear                                                       |\n",
      "|12         |1467812723|2009-04-07|NO_QUERY|TLeC           |caregiving,couldn,bear,watch,thought,ua,loss,wa,embarrassing         |\n",
      "|13         |1467812771|2009-04-07|NO_QUERY|robrobbierobert|octolinz16,count,idk,either,never,talk,anymore                       |\n",
      "|14         |1467812784|2009-04-07|NO_QUERY|bayofwolves    |smarrison,ve,first,didn,gun,really,though,zac,snyder,doucheclown     |\n",
      "|15         |1467812799|2009-04-07|NO_QUERY|HairByJess     |iamjazzyfizzle,wish,got,watch,miss,iamlilnicki,wa,premiere           |\n",
      "|16         |1467812964|2009-04-07|NO_QUERY|lovesongwriter |hollis,death,scene,hurt,severely,watch,film,wry,director,cut         |\n",
      "|17         |1467813137|2009-04-07|NO_QUERY|armotley       |file,tax                                                             |\n",
      "|18         |1467813579|2009-04-07|NO_QUERY|starkissed     |lettya,ahh,ive,always,wanted,see,rent,love,soundtrack                |\n",
      "|19         |1467813782|2009-04-07|NO_QUERY|gi_gi_bee      |fakerpattypattz,oh,dear,drinking,forgotten,table,drink               |\n",
      "|20         |1467813985|2009-04-07|NO_QUERY|quanvu         |alydesigns,wa,day,didn,get,much,done                                 |\n",
      "+-----------+----------+----------+--------+---------------+---------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.select('tweet_index', 'ids', 'date', 'flag', 'user', 'concatenated_words')\n",
    "df.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb94110a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet_index: integer (nullable = true)\n",
      " |-- ids: long (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- concatenated_words: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ebaf4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysql_url = \"jdbc:mysql://localhost:3306/ProjectTweets\"\n",
    "mysql_properties = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"password\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b60333aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.write.jdbc(url=mysql_url, table=\"Tweets\", mode=\"overwrite\", properties=mysql_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9bfcd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+--------+---------------+--------------------+\n",
      "|tweet_index|       ids|      date|    flag|           user|  concatenated_words|\n",
      "+-----------+----------+----------+--------+---------------+--------------------+\n",
      "|          1|1467810672|2009-04-07|NO_QUERY|  scotthamilton|upset,update,face...|\n",
      "|          2|1467810917|2009-04-07|NO_QUERY|       mattycus|kenichan,dived,ma...|\n",
      "|          3|1467811184|2009-04-07|NO_QUERY|        ElleCTF|whole,body,feel,i...|\n",
      "|          4|1467811193|2009-04-07|NO_QUERY|         Karoli|nationwideclass,b...|\n",
      "|          5|1467811372|2009-04-07|NO_QUERY|       joy_wolf| kwesidei,whole,crew|\n",
      "|          6|1467811592|2009-04-07|NO_QUERY|        mybirch|            need,hug|\n",
      "|          7|1467811594|2009-04-07|NO_QUERY|           coZZ|loltrish,hey,long...|\n",
      "|          8|1467811795|2009-04-07|NO_QUERY|2Hood4Hollywood| tatiana,k,nope,didn|\n",
      "|          9|1467812025|2009-04-07|NO_QUERY|        mimismo|  twittera,que,muera|\n",
      "|         10|1467812416|2009-04-07|NO_QUERY| erinx3leannexo|spring,break,plai...|\n",
      "|         11|1467812579|2009-04-07|NO_QUERY|   pardonlauren|      re,pierced,ear|\n",
      "|         12|1467812723|2009-04-07|NO_QUERY|           TLeC|caregiving,couldn...|\n",
      "|         13|1467812771|2009-04-07|NO_QUERY|robrobbierobert|octolinz16,count,...|\n",
      "|         14|1467812784|2009-04-07|NO_QUERY|    bayofwolves|smarrison,ve,firs...|\n",
      "|         15|1467812799|2009-04-07|NO_QUERY|     HairByJess|iamjazzyfizzle,wi...|\n",
      "|         16|1467812964|2009-04-07|NO_QUERY| lovesongwriter|hollis,death,scen...|\n",
      "|         17|1467813137|2009-04-07|NO_QUERY|       armotley|            file,tax|\n",
      "|         18|1467813579|2009-04-07|NO_QUERY|     starkissed|lettya,ahh,ive,al...|\n",
      "|         19|1467813782|2009-04-07|NO_QUERY|      gi_gi_bee|fakerpattypattz,o...|\n",
      "|         20|1467813985|2009-04-07|NO_QUERY|         quanvu|alydesigns,wa,day...|\n",
      "+-----------+----------+----------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_from_mysql = spark.read.jdbc(url=mysql_url, table=\"Tweets\", properties=mysql_properties)\n",
    "df_from_mysql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee114bb",
   "metadata": {},
   "source": [
    "# Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8215b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"temp_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f96c9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 01:13:56,415 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-11-05 01:13:56,420 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-11-05 01:14:07,924 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "2023-11-05 01:14:07,925 WARN metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore hduser@127.0.1.1\n",
      "2023-11-05 01:14:07,961 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException\n",
      "2023-11-05 01:14:09,838 WARN session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "2023-11-05 01:14:09,914 WARN conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "2023-11-05 01:14:09,915 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-11-05 01:14:09,915 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-11-05 01:14:09,937 WARN metastore.HiveMetaStore: Location: file:/home/hduser/CA2/spark-warehouse/projecttweets specified for non-external table:projecttweets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_table_sql = \"\"\"\n",
    "CREATE TABLE ProjectTweets (\n",
    "    tweet_index INT,\n",
    "    ids BIGINT,\n",
    "    date DATE,\n",
    "    flag STRING,\n",
    "    user STRING,\n",
    "    filtered_words_final STRING\n",
    ")\n",
    "STORED AS PARQUET\n",
    "\"\"\"\n",
    "spark.sql(create_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e014f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hive_insert_data_sql = \"\"\"\n",
    "INSERT INTO ProjectTweets SELECT * FROM temp_table\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86a95903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 01:16:19,343 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(hive_insert_data_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d910743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+--------+---------------+--------------------+\n",
      "|tweet_index|       ids|      date|    flag|           user|filtered_words_final|\n",
      "+-----------+----------+----------+--------+---------------+--------------------+\n",
      "|          1|1467810672|2009-04-07|NO_QUERY|  scotthamilton|upset,update,face...|\n",
      "|          2|1467810917|2009-04-07|NO_QUERY|       mattycus|kenichan,dived,ma...|\n",
      "|          3|1467811184|2009-04-07|NO_QUERY|        ElleCTF|whole,body,feel,i...|\n",
      "|          4|1467811193|2009-04-07|NO_QUERY|         Karoli|nationwideclass,b...|\n",
      "|          5|1467811372|2009-04-07|NO_QUERY|       joy_wolf| kwesidei,whole,crew|\n",
      "|          6|1467811592|2009-04-07|NO_QUERY|        mybirch|            need,hug|\n",
      "|          7|1467811594|2009-04-07|NO_QUERY|           coZZ|loltrish,hey,long...|\n",
      "|          8|1467811795|2009-04-07|NO_QUERY|2Hood4Hollywood| tatiana,k,nope,didn|\n",
      "|          9|1467812025|2009-04-07|NO_QUERY|        mimismo|  twittera,que,muera|\n",
      "|         10|1467812416|2009-04-07|NO_QUERY| erinx3leannexo|spring,break,plai...|\n",
      "|         11|1467812579|2009-04-07|NO_QUERY|   pardonlauren|      re,pierced,ear|\n",
      "|         12|1467812723|2009-04-07|NO_QUERY|           TLeC|caregiving,couldn...|\n",
      "|         13|1467812771|2009-04-07|NO_QUERY|robrobbierobert|octolinz16,count,...|\n",
      "|         14|1467812784|2009-04-07|NO_QUERY|    bayofwolves|smarrison,ve,firs...|\n",
      "|         15|1467812799|2009-04-07|NO_QUERY|     HairByJess|iamjazzyfizzle,wi...|\n",
      "|         16|1467812964|2009-04-07|NO_QUERY| lovesongwriter|hollis,death,scen...|\n",
      "|         17|1467813137|2009-04-07|NO_QUERY|       armotley|            file,tax|\n",
      "|         18|1467813579|2009-04-07|NO_QUERY|     starkissed|lettya,ahh,ive,al...|\n",
      "|         19|1467813782|2009-04-07|NO_QUERY|      gi_gi_bee|fakerpattypattz,o...|\n",
      "|         20|1467813985|2009-04-07|NO_QUERY|         quanvu|alydesigns,wa,day...|\n",
      "+-----------+----------+----------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Veriyi sorgulayın\n",
    "result = spark.sql(\"SELECT * FROM ProjectTweets\")\n",
    "\n",
    "# Sonuçları gösterin\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f1b93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf6cc0f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '£' (U+00A3) (2277693821.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_9847/2277693821.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ££fd.amglamha\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '£' (U+00A3)\n"
     ]
    }
   ],
   "source": [
    "££fd.amglamha\n",
    "mmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c163d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b7c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d850c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c453055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f323ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd5341d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c741aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f5430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check flag column distribution\n",
    "def create_bar_chart(df):\n",
    "    flag_counts = df.groupBy(\"flag\").count().orderBy(\"flag\")\n",
    "    x = flag_counts.select(\"flag\").rdd.flatMap(lambda x: x).collect()\n",
    "    y = flag_counts.select(\"count\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "    data = [go.Bar(x=x, y=y)]\n",
    "\n",
    "    layout = go.Layout(title=\"Flag Distribution\", xaxis=dict(title=\"Flag\"), yaxis=dict(title=\"Count\"))\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Dash uygulamasını oluşturun\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(id='flag-chart'),\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('flag-chart', 'figure'),\n",
    "    [Input('flag-chart', 'relayoutData')]\n",
    ")\n",
    "def update_chart(relayoutData):\n",
    "    return create_bar_chart(df)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1387b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
