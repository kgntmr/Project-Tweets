{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac2e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "spark = SparkSession.builder.appName('ProjectTweets').enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf717f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9638/4273979666.py:12: UserWarning: \n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "  import dash_core_components as dcc\n",
      "/tmp/ipykernel_9638/4273979666.py:13: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace, col, lower\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pyspark.sql.functions import udf\n",
    "from pymongo import MongoClient\n",
    "from pyspark.sql.types import StringType\n",
    "import nltk\n",
    "#nltk.download('omw-1.4')\n",
    "#nltk.download('wordnet')\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ffa58",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91573341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('/user1/ProjectTweets.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61bd395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: integer (nullable = true)\n",
      " |-- 1467810369: long (nullable = true)\n",
      " |-- Mon Apr 06 22:19:45 PDT 2009: string (nullable = true)\n",
      " |-- NO_QUERY: string (nullable = true)\n",
      " |-- _TheSpecialOne_: string (nullable = true)\n",
      " |-- @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5363c840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|0  |1467810369|Mon Apr 06 22:19:45 PDT 2009|NO_QUERY|_TheSpecialOne_|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |1467810672|Mon Apr 06 22:19:49 PDT 2009|NO_QUERY|scotthamilton  |is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!    |\n",
      "|2  |1467810917|Mon Apr 06 22:19:53 PDT 2009|NO_QUERY|mattycus       |@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                          |\n",
      "|3  |1467811184|Mon Apr 06 22:19:57 PDT 2009|NO_QUERY|ElleCTF        |my whole body feels itchy and like its on fire                                                                     |\n",
      "|4  |1467811193|Mon Apr 06 22:19:57 PDT 2009|NO_QUERY|Karoli         |@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.     |\n",
      "|5  |1467811372|Mon Apr 06 22:20:00 PDT 2009|NO_QUERY|joy_wolf       |@Kwesidei not the whole crew                                                                                       |\n",
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a60c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c358289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = ['ids', 'date', 'flag', 'user', 'text']\n",
    "\n",
    "for i, column_name in enumerate(new_cols):\n",
    "    df = df.withColumnRenamed(df.columns[i + 1], column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31d1f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb99dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.legacy.timeParserPolicy', 'LEGACY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f77ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_column = df.select('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2baf2eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('date', to_date(df['date'], 'EEE MMM dd HH:mm:ss zzz yyyy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a856b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('date', to_date(col('date'), 'dd/MM/yyyy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06d9721a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------+---------------+--------------------+\n",
      "|  0|       ids|      date|    flag|           user|                text|\n",
      "+---+----------+----------+--------+---------------+--------------------+\n",
      "|  1|1467810672|2009-04-07|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|  2|1467810917|2009-04-07|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|  3|1467811184|2009-04-07|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|  4|1467811193|2009-04-07|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|  5|1467811372|2009-04-07|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|  6|1467811592|2009-04-07|NO_QUERY|        mybirch|         Need a hug |\n",
      "|  7|1467811594|2009-04-07|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|  8|1467811795|2009-04-07|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|  9|1467812025|2009-04-07|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "| 10|1467812416|2009-04-07|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "| 11|1467812579|2009-04-07|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "| 12|1467812723|2009-04-07|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "| 13|1467812771|2009-04-07|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "| 14|1467812784|2009-04-07|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "| 15|1467812799|2009-04-07|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "| 16|1467812964|2009-04-07|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "| 17|1467813137|2009-04-07|NO_QUERY|       armotley|about to file taxes |\n",
      "| 18|1467813579|2009-04-07|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "| 19|1467813782|2009-04-07|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "| 20|1467813985|2009-04-07|NO_QUERY|         quanvu|@alydesigns i was...|\n",
      "+---+----------+----------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28086db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: integer (nullable = true)\n",
      " |-- ids: long (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "572dff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data to lowercase and clean unnecessary characters\n",
    "df = df.withColumn(\"text\", lower(regexp_replace(col(\"text\"), \"[^a-zA-Z0-9\\\\s]\", \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fc3289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special symbols, and links from text data\n",
    "df = df.withColumn(\"text\", regexp_replace(col(\"text\"), r'[@#]\\w+|https?://\\S+|\\W', \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e34447de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------+-------------+---------------------------------------------------------------------------------------------------------------+\n",
      "|0  |ids       |date      |flag    |user         |text                                                                                                           |\n",
      "+---+----------+----------+--------+-------------+---------------------------------------------------------------------------------------------------------------+\n",
      "|1  |1467810672|2009-04-07|NO_QUERY|scotthamilton|is upset that he can t update his facebook by texting it    and might cry as a result  school today also  blah |\n",
      "+---+----------+----------+--------+-------------+---------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cb97431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization using NLTK\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "lemmatize_udf = udf(lemmatize_text, StringType())\n",
    "df = df.withColumn(\"text\", lemmatize_udf(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "595fcaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"filtered_words\")\n",
    "df = tokenizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb950b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------+-------------+--------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0  |ids       |date      |flag    |user         |text                                                                                                    |filtered_words                                                                                                                 |\n",
      "+---+----------+----------+--------+-------------+--------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |1467810672|2009-04-07|NO_QUERY|scotthamilton|is upset that he can t update his facebook by texting it and might cry a a result school today also blah|[is, upset, that, he, can, t, update, his, facebook, by, texting, it, and, might, cry, a, a, result, school, today, also, blah]|\n",
      "+---+----------+----------+--------+-------------+--------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df0794fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use StopWordsRemover on the \"filtered_words\" column in your example DataFrame\n",
    "remover = StopWordsRemover(inputCol=\"filtered_words\", outputCol=\"filtered_words_without_stopwords\")\n",
    "df = remover.transform(df)\n",
    "\n",
    "# You can update the column name as per your needs\n",
    "df = df.withColumnRenamed(\"filtered_words_without_stopwords\", \"filtered_words_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7435bdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+--------+---------------+---------------------------------------------------------------------------------+\n",
      "|tweet_index|ids       |date      |flag    |user           |filtered_words_final                                                             |\n",
      "+-----------+----------+----------+--------+---------------+---------------------------------------------------------------------------------+\n",
      "|1          |1467810672|2009-04-07|NO_QUERY|scotthamilton  |[upset, update, facebook, texting, might, cry, result, school, today, also, blah]|\n",
      "|2          |1467810917|2009-04-07|NO_QUERY|mattycus       |[kenichan, dived, many, time, ball, managed, save, 50, rest, go, bound]          |\n",
      "|3          |1467811184|2009-04-07|NO_QUERY|ElleCTF        |[whole, body, feel, itchy, like, fire]                                           |\n",
      "|4          |1467811193|2009-04-07|NO_QUERY|Karoli         |[nationwideclass, behaving, m, mad, see]                                         |\n",
      "|5          |1467811372|2009-04-07|NO_QUERY|joy_wolf       |[kwesidei, whole, crew]                                                          |\n",
      "|6          |1467811592|2009-04-07|NO_QUERY|mybirch        |[need, hug]                                                                      |\n",
      "|7          |1467811594|2009-04-07|NO_QUERY|coZZ           |[loltrish, hey, long, time, see, yes, rain, bit, bit, lol, m, fine, thanks]      |\n",
      "|8          |1467811795|2009-04-07|NO_QUERY|2Hood4Hollywood|[tatiana, k, nope, didn]                                                         |\n",
      "|9          |1467812025|2009-04-07|NO_QUERY|mimismo        |[twittera, que, muera]                                                           |\n",
      "|10         |1467812416|2009-04-07|NO_QUERY|erinx3leannexo |[spring, break, plain, city, snowing]                                            |\n",
      "|11         |1467812579|2009-04-07|NO_QUERY|pardonlauren   |[re, pierced, ear]                                                               |\n",
      "|12         |1467812723|2009-04-07|NO_QUERY|TLeC           |[caregiving, couldn, bear, watch, thought, ua, loss, wa, embarrassing]           |\n",
      "|13         |1467812771|2009-04-07|NO_QUERY|robrobbierobert|[octolinz16, count, idk, either, never, talk, anymore]                           |\n",
      "|14         |1467812784|2009-04-07|NO_QUERY|bayofwolves    |[smarrison, ve, first, didn, gun, really, though, zac, snyder, doucheclown]      |\n",
      "|15         |1467812799|2009-04-07|NO_QUERY|HairByJess     |[iamjazzyfizzle, wish, got, watch, miss, iamlilnicki, wa, premiere]              |\n",
      "|16         |1467812964|2009-04-07|NO_QUERY|lovesongwriter |[hollis, death, scene, hurt, severely, watch, film, wry, director, cut]          |\n",
      "|17         |1467813137|2009-04-07|NO_QUERY|armotley       |[file, tax]                                                                      |\n",
      "|18         |1467813579|2009-04-07|NO_QUERY|starkissed     |[lettya, ahh, ive, always, wanted, see, rent, love, soundtrack]                  |\n",
      "|19         |1467813782|2009-04-07|NO_QUERY|gi_gi_bee      |[fakerpattypattz, oh, dear, drinking, forgotten, table, drink]                   |\n",
      "|20         |1467813985|2009-04-07|NO_QUERY|quanvu         |[alydesigns, wa, day, didn, get, much, done]                                     |\n",
      "+-----------+----------+----------+--------+---------------+---------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Just pick the necessary columns\n",
    "df = df.select('0', 'ids', 'date', 'flag', 'user', 'filtered_words_final')\n",
    "\n",
    "# Rename the \"0\" column to \"index\"\n",
    "df = df.withColumnRenamed(\"0\", \"tweet_index\")\n",
    "\n",
    "# Show the result\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba62fe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+--------+---------------+--------------------+\n",
      "|tweet_index|       ids|      date|    flag|           user|filtered_words_final|\n",
      "+-----------+----------+----------+--------+---------------+--------------------+\n",
      "|          1|1467810672|2009-04-07|NO_QUERY|  scotthamilton|[upset, update, f...|\n",
      "|          2|1467810917|2009-04-07|NO_QUERY|       mattycus|[kenichan, dived,...|\n",
      "|          3|1467811184|2009-04-07|NO_QUERY|        ElleCTF|[whole, body, fee...|\n",
      "|          4|1467811193|2009-04-07|NO_QUERY|         Karoli|[nationwideclass,...|\n",
      "|          5|1467811372|2009-04-07|NO_QUERY|       joy_wolf|[kwesidei, whole,...|\n",
      "|          6|1467811592|2009-04-07|NO_QUERY|        mybirch|         [need, hug]|\n",
      "|          7|1467811594|2009-04-07|NO_QUERY|           coZZ|[loltrish, hey, l...|\n",
      "|          8|1467811795|2009-04-07|NO_QUERY|2Hood4Hollywood|[tatiana, k, nope...|\n",
      "|          9|1467812025|2009-04-07|NO_QUERY|        mimismo|[twittera, que, m...|\n",
      "|         10|1467812416|2009-04-07|NO_QUERY| erinx3leannexo|[spring, break, p...|\n",
      "|         11|1467812579|2009-04-07|NO_QUERY|   pardonlauren|  [re, pierced, ear]|\n",
      "|         12|1467812723|2009-04-07|NO_QUERY|           TLeC|[caregiving, coul...|\n",
      "|         13|1467812771|2009-04-07|NO_QUERY|robrobbierobert|[octolinz16, coun...|\n",
      "|         14|1467812784|2009-04-07|NO_QUERY|    bayofwolves|[smarrison, ve, f...|\n",
      "|         15|1467812799|2009-04-07|NO_QUERY|     HairByJess|[iamjazzyfizzle, ...|\n",
      "|         16|1467812964|2009-04-07|NO_QUERY| lovesongwriter|[hollis, death, s...|\n",
      "|         17|1467813137|2009-04-07|NO_QUERY|       armotley|         [file, tax]|\n",
      "|         18|1467813579|2009-04-07|NO_QUERY|     starkissed|[lettya, ahh, ive...|\n",
      "|         19|1467813782|2009-04-07|NO_QUERY|      gi_gi_bee|[fakerpattypattz,...|\n",
      "|         20|1467813985|2009-04-07|NO_QUERY|         quanvu|[alydesigns, wa, ...|\n",
      "+-----------+----------+----------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.dropna().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1281d496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of values in the dataframe 1599999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the total number of values in the dataframe\n",
    "total_count = df.count()\n",
    "\n",
    "# Show the total count\n",
    "print(\"Total count of values in the dataframe\", total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "636066b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checking the value inside flag column\n",
    "\n",
    "# # Let's check flag column distribution\n",
    "# def create_bar_chart(df):\n",
    "#     flag_counts = df.groupBy(\"flag\").count().orderBy(\"flag\")\n",
    "#     x = flag_counts.select(\"flag\").rdd.flatMap(lambda x: x).collect()\n",
    "#     y = flag_counts.select(\"count\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "#     data = [go.Bar(x=x, y=y)]\n",
    "\n",
    "#     layout = go.Layout(title=\"Flag Distribution\", xaxis=dict(title=\"Flag\"), yaxis=dict(title=\"Count\"))\n",
    "#     fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# # Dash uygulamasını oluşturun\n",
    "# app = dash.Dash(__name__)\n",
    "\n",
    "# app.layout = html.Div([\n",
    "#     dcc.Graph(id='flag-chart'),\n",
    "# ])\n",
    "\n",
    "# @app.callback(\n",
    "#     Output('flag-chart', 'figure'),\n",
    "#     [Input('flag-chart', 'relayoutData')]\n",
    "# )\n",
    "# def update_chart(relayoutData):\n",
    "#     return create_bar_chart(df)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79986ea3",
   "metadata": {},
   "source": [
    "# MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd55fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "# Connect to the database\n",
    "connection = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"password\",\n",
    "    database=\"ProjectTweets\",\n",
    "    charset='utf8mb4',\n",
    "    cursorclass=pymysql.cursors.DictCursor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f13a6c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a cursor\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# # Create a table\n",
    "# create_table_sql = \"\"\"\n",
    "# CREATE TABLE Tweets (\n",
    "#     tweet_index INT AUTO_INCREMENT PRIMARY KEY,\n",
    "#     ids BIGINT,\n",
    "#     date DATE,\n",
    "#     flag VARCHAR(55),\n",
    "#     user VARCHAR(255),\n",
    "#     filtered_words_final TEXT\n",
    "# );\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9ed8b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table\n",
    "#cursor.execute(create_table_sql)\n",
    "\n",
    "# Save changes\n",
    "#connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36c36c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet_index: integer (nullable = true)\n",
      " |-- ids: long (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- filtered_words_final: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70aeee81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet_index: integer (nullable = true)\n",
      " |-- ids: long (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- filtered_words_final: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- concatenated_words: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 'filtered_words_final' adındaki sütunu virgülle ayrılmış bir metin sütunu olarak birleştirin.\n",
    "df = df.withColumn('concatenated_words', concat_ws(\",\", df['filtered_words_final']))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3078f1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+--------+-------------+---------------------------------------------------------------------+\n",
      "|tweet_index|ids       |date      |flag    |user         |concatenated_words                                                   |\n",
      "+-----------+----------+----------+--------+-------------+---------------------------------------------------------------------+\n",
      "|1          |1467810672|2009-04-07|NO_QUERY|scotthamilton|upset,update,facebook,texting,might,cry,result,school,today,also,blah|\n",
      "+-----------+----------+----------+--------+-------------+---------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.select('tweet_index', 'ids', 'date', 'flag', 'user', 'concatenated_words')\n",
    "df.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb94110a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet_index: integer (nullable = true)\n",
      " |-- ids: long (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- concatenated_words: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ebaf4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysql_url = \"jdbc:mysql://localhost:3306/ProjectTweets\"\n",
    "mysql_properties = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"password\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b60333aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.write.jdbc(url=mysql_url, table=\"Tweets\", mode=\"overwrite\", properties=mysql_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6ed197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ALTER TABLE sorgusunu çalıştır\n",
    "# alter_table_sql = \"ALTER TABLE Tweets ADD COLUMN YCSB_KEY VARCHAR(255);\"\n",
    "# cursor.execute(alter_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc894c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Değişiklikleri kaydet\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c638b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_mysql = spark.read.jdbc(url=mysql_url, table=\"Tweets\", properties=mysql_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdd4815d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+--------+---------------+--------------------+--------+\n",
      "|tweet_index|       ids|      date|    flag|           user|  concatenated_words|YCSB_KEY|\n",
      "+-----------+----------+----------+--------+---------------+--------------------+--------+\n",
      "|          1|1467810672|2009-04-07|NO_QUERY|  scotthamilton|upset,update,face...|    null|\n",
      "|          2|1467810917|2009-04-07|NO_QUERY|       mattycus|kenichan,dived,ma...|    null|\n",
      "|          3|1467811184|2009-04-07|NO_QUERY|        ElleCTF|whole,body,feel,i...|    null|\n",
      "|          4|1467811193|2009-04-07|NO_QUERY|         Karoli|nationwideclass,b...|    null|\n",
      "|          5|1467811372|2009-04-07|NO_QUERY|       joy_wolf| kwesidei,whole,crew|    null|\n",
      "|          6|1467811592|2009-04-07|NO_QUERY|        mybirch|            need,hug|    null|\n",
      "|          7|1467811594|2009-04-07|NO_QUERY|           coZZ|loltrish,hey,long...|    null|\n",
      "|          8|1467811795|2009-04-07|NO_QUERY|2Hood4Hollywood| tatiana,k,nope,didn|    null|\n",
      "|          9|1467812025|2009-04-07|NO_QUERY|        mimismo|  twittera,que,muera|    null|\n",
      "|         10|1467812416|2009-04-07|NO_QUERY| erinx3leannexo|spring,break,plai...|    null|\n",
      "|         11|1467812579|2009-04-07|NO_QUERY|   pardonlauren|      re,pierced,ear|    null|\n",
      "|         12|1467812723|2009-04-07|NO_QUERY|           TLeC|caregiving,couldn...|    null|\n",
      "|         13|1467812771|2009-04-07|NO_QUERY|robrobbierobert|octolinz16,count,...|    null|\n",
      "|         14|1467812784|2009-04-07|NO_QUERY|    bayofwolves|smarrison,ve,firs...|    null|\n",
      "|         15|1467812799|2009-04-07|NO_QUERY|     HairByJess|iamjazzyfizzle,wi...|    null|\n",
      "|         16|1467812964|2009-04-07|NO_QUERY| lovesongwriter|hollis,death,scen...|    null|\n",
      "|         17|1467813137|2009-04-07|NO_QUERY|       armotley|            file,tax|    null|\n",
      "|         18|1467813579|2009-04-07|NO_QUERY|     starkissed|lettya,ahh,ive,al...|    null|\n",
      "|         19|1467813782|2009-04-07|NO_QUERY|      gi_gi_bee|fakerpattypattz,o...|    null|\n",
      "|         20|1467813985|2009-04-07|NO_QUERY|         quanvu|alydesigns,wa,day...|    null|\n",
      "+-----------+----------+----------+--------+---------------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_from_mysql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a1206f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a cursor\n",
    "# cursor = connection.cursor()\n",
    "\n",
    "# # Create a table\n",
    "# create_table_sql = \"\"\"\n",
    "# CREATE TABLE YCSB_TEST (\n",
    "#     tweet_index INT AUTO_INCREMENT PRIMARY KEY,\n",
    "#     ids BIGINT,\n",
    "#     date DATE,\n",
    "#     flag VARCHAR(55),\n",
    "#     user VARCHAR(255),\n",
    "#     filtered_words_final TEXT,\n",
    "#     YCSB_KEY VARCHAR(255)\n",
    "# );\n",
    "# \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c2d8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create a table\n",
    "# cursor.execute(create_table_sql)\n",
    "\n",
    "# #Save changes\n",
    "# connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850bbc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e817ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb6340c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YCSB operation completed successfully.\n",
      "Output:\n",
      "/usr/bin/java  -classpath /home/hduser/ycsb-0.17.0/conf:/home/hduser/ycsb-0.17.0/lib/HdrHistogram-2.1.4.jar:/home/hduser/ycsb-0.17.0/lib/core-0.17.0.jar:/home/hduser/ycsb-0.17.0/lib/htrace-core4-4.1.0-incubating.jar:/home/hduser/ycsb-0.17.0/lib/jackson-core-asl-1.9.4.jar:/home/hduser/ycsb-0.17.0/lib/jackson-mapper-asl-1.9.4.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/conf:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/commons-collections-3.2.1.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/commons-lang-2.4.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/commons-pool-1.5.4.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/geronimo-jms_1.1_spec-1.1.1.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/geronimo-jta_1.1_spec-1.1.1.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/jdbc-binding-0.17.0.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/mysql-connector-j-8.0.33.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/mysql-connector-java-8.0.30.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/openjpa-jdbc-2.1.1.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/openjpa-kernel-2.1.1.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/openjpa-lib-2.1.1.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/serp-1.13.1.jar site.ycsb.Client -load -db site.ycsb.db.JdbcDBClient -P /home/hduser/ycsb-0.17.0/jdbc-binding/conf/db.properties -P /home/hduser/ycsb-0.17.0/workloads/workloada -p db.connection_properties=user=root&password=password&useSSL=false -p jdbc.url=jdbc:mysql://localhost:3306/ProjectTweets -p table=YCSB_TEST\n",
      "Adding shard node URL: jdbc:mysql://localhost:3306/ProjectTweets\n",
      "Using shards: 1, batchSize:-1, fetchSize: -1\n",
      "[OVERALL], RunTime(ms), 1457\n",
      "[OVERALL], Throughput(ops/sec), 0.0\n",
      "[TOTAL_GCS_Copy], Count, 0\n",
      "[TOTAL_GC_TIME_Copy], Time(ms), 0\n",
      "[TOTAL_GC_TIME_%_Copy], Time(%), 0.0\n",
      "[TOTAL_GCS_MarkSweepCompact], Count, 0\n",
      "[TOTAL_GC_TIME_MarkSweepCompact], Time(ms), 0\n",
      "[TOTAL_GC_TIME_%_MarkSweepCompact], Time(%), 0.0\n",
      "[TOTAL_GCs], Count, 0\n",
      "[TOTAL_GC_TIME], Time(ms), 0\n",
      "[TOTAL_GC_TIME_%], Time(%), 0.0\n",
      "[CLEANUP], Operations, 1\n",
      "[CLEANUP], AverageLatency(us), 3251.0\n",
      "[CLEANUP], MinLatency(us), 3250\n",
      "[CLEANUP], MaxLatency(us), 3251\n",
      "[CLEANUP], 95thPercentileLatency(us), 3251\n",
      "[CLEANUP], 99thPercentileLatency(us), 3251\n",
      "[INSERT], Operations, 0\n",
      "[INSERT], AverageLatency(us), NaN\n",
      "[INSERT], MinLatency(us), 9223372036854775807\n",
      "[INSERT], MaxLatency(us), 0\n",
      "[INSERT], 95thPercentileLatency(us), 0\n",
      "[INSERT], 99thPercentileLatency(us), 0\n",
      "[INSERT], Return=ERROR, 1\n",
      "[INSERT-FAILED], Operations, 1\n",
      "[INSERT-FAILED], AverageLatency(us), 72544.0\n",
      "[INSERT-FAILED], MinLatency(us), 72512\n",
      "[INSERT-FAILED], MaxLatency(us), 72575\n",
      "[INSERT-FAILED], 95thPercentileLatency(us), 72575\n",
      "[INSERT-FAILED], 99thPercentileLatency(us), 72575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "command = \"/home/hduser/ycsb-0.17.0/bin/ycsb.sh load jdbc -P /home/hduser/ycsb-0.17.0/jdbc-binding/conf/db.properties -P /home/hduser/ycsb-0.17.0/workloads/workloada -p db.connection_properties=\\\"user=root&password=password&useSSL=false\\\" -p jdbc.url=jdbc:mysql://localhost:3306/ProjectTweets -p table=YCSB_TEST\"\n",
    "\n",
    "process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "if process.returncode == 0:\n",
    "    print(\"YCSB operation completed successfully.\")\n",
    "    print(\"Output:\")\n",
    "    print(stdout.decode('utf-8'))\n",
    "else:\n",
    "    print(\"YCSB operation failed. Error message:\")\n",
    "    print(stderr.decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8353813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+--------+---------------+--------------------+--------+\n",
      "|tweet_index|       ids|      date|    flag|           user|  concatenated_words|YCSB_KEY|\n",
      "+-----------+----------+----------+--------+---------------+--------------------+--------+\n",
      "|          1|1467810672|2009-04-07|NO_QUERY|  scotthamilton|upset,update,face...|    null|\n",
      "|          2|1467810917|2009-04-07|NO_QUERY|       mattycus|kenichan,dived,ma...|    null|\n",
      "|          3|1467811184|2009-04-07|NO_QUERY|        ElleCTF|whole,body,feel,i...|    null|\n",
      "|          4|1467811193|2009-04-07|NO_QUERY|         Karoli|nationwideclass,b...|    null|\n",
      "|          5|1467811372|2009-04-07|NO_QUERY|       joy_wolf| kwesidei,whole,crew|    null|\n",
      "|          6|1467811592|2009-04-07|NO_QUERY|        mybirch|            need,hug|    null|\n",
      "|          7|1467811594|2009-04-07|NO_QUERY|           coZZ|loltrish,hey,long...|    null|\n",
      "|          8|1467811795|2009-04-07|NO_QUERY|2Hood4Hollywood| tatiana,k,nope,didn|    null|\n",
      "|          9|1467812025|2009-04-07|NO_QUERY|        mimismo|  twittera,que,muera|    null|\n",
      "|         10|1467812416|2009-04-07|NO_QUERY| erinx3leannexo|spring,break,plai...|    null|\n",
      "|         11|1467812579|2009-04-07|NO_QUERY|   pardonlauren|      re,pierced,ear|    null|\n",
      "|         12|1467812723|2009-04-07|NO_QUERY|           TLeC|caregiving,couldn...|    null|\n",
      "|         13|1467812771|2009-04-07|NO_QUERY|robrobbierobert|octolinz16,count,...|    null|\n",
      "|         14|1467812784|2009-04-07|NO_QUERY|    bayofwolves|smarrison,ve,firs...|    null|\n",
      "|         15|1467812799|2009-04-07|NO_QUERY|     HairByJess|iamjazzyfizzle,wi...|    null|\n",
      "|         16|1467812964|2009-04-07|NO_QUERY| lovesongwriter|hollis,death,scen...|    null|\n",
      "|         17|1467813137|2009-04-07|NO_QUERY|       armotley|            file,tax|    null|\n",
      "|         18|1467813579|2009-04-07|NO_QUERY|     starkissed|lettya,ahh,ive,al...|    null|\n",
      "|         19|1467813782|2009-04-07|NO_QUERY|      gi_gi_bee|fakerpattypattz,o...|    null|\n",
      "|         20|1467813985|2009-04-07|NO_QUERY|         quanvu|alydesigns,wa,day...|    null|\n",
      "+-----------+----------+----------+--------+---------------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_from_mysql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9c94311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet_index: integer (nullable = true)\n",
      " |-- ids: long (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- concatenated_words: string (nullable = true)\n",
      " |-- YCSB_KEY: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_from_mysql.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c9c746",
   "metadata": {},
   "source": [
    "### Due to a technical Issue I decided to use cProfile instead of YCSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4eb24e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Örnek bir sorgu\n",
    "query = \"SELECT * FROM Tweets WHERE concatenated_words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c6d222c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1131257 function calls in 2.395 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    2.395    2.395 {built-in method builtins.exec}\n",
      "        1    0.002    0.002    2.395    2.395 <string>:1(<module>)\n",
      "        1    0.000    0.000    2.394    2.394 3302925674.py:3(perform_query)\n",
      "        1    0.000    0.000    2.394    2.394 cursors.py:133(execute)\n",
      "        1    0.000    0.000    2.393    2.393 cursors.py:319(_query)\n",
      "        1    0.000    0.000    2.372    2.372 connections.py:552(query)\n",
      "        1    0.000    0.000    2.361    2.361 connections.py:810(_read_query_result)\n",
      "        1    0.000    0.000    2.361    2.361 connections.py:1198(read)\n",
      "        1    0.000    0.000    2.330    2.330 connections.py:1281(_read_result_packet)\n",
      "        1    0.038    0.038    2.329    2.329 connections.py:1327(_read_rowdata_packet)\n",
      "    16867    0.070    0.000    1.635    0.000 connections.py:730(_read_packet)\n",
      "    33734    0.106    0.000    1.551    0.000 connections.py:775(_read_bytes)\n",
      "    33734    0.012    0.000    1.409    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
      "      221    0.001    0.000    1.397    0.006 socket.py:691(readinto)\n",
      "      221    1.396    0.006    1.396    0.006 {method 'recv_into' of '_socket.socket' objects}\n",
      "    16857    0.169    0.000    0.677    0.000 connections.py:1340(_read_row_from_packet)\n",
      "   118041    0.107    0.000    0.393    0.000 protocol.py:165(read_length_coded_string)\n",
      "   118042    0.104    0.000    0.157    0.000 protocol.py:147(read_length_encoded_integer)\n",
      "   101184    0.098    0.000    0.128    0.000 protocol.py:62(read)\n",
      "    16857    0.050    0.000    0.074    0.000 converters.py:281(convert_date)\n",
      "   118042    0.053    0.000    0.053    0.000 protocol.py:114(read_uint8)\n",
      "    33735    0.033    0.000    0.033    0.000 {method 'settimeout' of '_socket.socket' objects}\n",
      "   134931    0.033    0.000    0.033    0.000 {built-in method builtins.len}\n",
      "   101170    0.030    0.000    0.030    0.000 {method 'decode' of 'bytes' objects}\n",
      "        1    0.000    0.000    0.021    0.021 cursors.py:385(_do_get_result)\n",
      "        1    0.004    0.004    0.021    0.021 cursors.py:397(<listcomp>)\n",
      "    16857    0.017    0.000    0.017    0.000 cursors.py:399(_conv_row)\n",
      "   134884    0.014    0.000    0.014    0.000 {method 'append' of 'list' objects}\n",
      "    16857    0.013    0.000    0.013    0.000 converters.py:297(<listcomp>)\n",
      "        8    0.012    0.001    0.012    0.001 {method 'sendall' of '_socket.socket' objects}\n",
      "        1    0.000    0.000    0.011    0.011 connections.py:834(_execute_command)\n",
      "        1    0.000    0.000    0.011    0.011 connections.py:800(_write_bytes)\n",
      "    16858    0.007    0.000    0.010    0.000 connections.py:1268(_check_packet_is_eof)\n",
      "    16857    0.006    0.000    0.006    0.000 {method 'split' of 'str' objects}\n",
      "    16867    0.005    0.000    0.005    0.000 {built-in method _struct.unpack}\n",
      "    16867    0.005    0.000    0.005    0.000 protocol.py:55(__init__)\n",
      "    16867    0.004    0.000    0.004    0.000 protocol.py:208(is_error_packet)\n",
      "    16894    0.004    0.000    0.004    0.000 {built-in method builtins.isinstance}\n",
      "    16860    0.003    0.000    0.003    0.000 protocol.py:187(is_eof_packet)\n",
      "        7    0.000    0.000    0.001    0.000 java_gateway.py:1340(<lambda>)\n",
      "        7    0.000    0.000    0.001    0.000 java_gateway.py:638(_garbage_collect_object)\n",
      "        7    0.000    0.000    0.001    0.000 java_gateway.py:956(garbage_collect_object)\n",
      "        7    0.000    0.000    0.001    0.000 java_gateway.py:1010(send_command)\n",
      "        7    0.000    0.000    0.001    0.000 java_gateway.py:1178(send_command)\n",
      "        1    0.000    0.000    0.000    0.000 connections.py:1359(_get_descriptions)\n",
      "      221    0.000    0.000    0.000    0.000 {method '_checkReadable' of '_io._IOBase' objects}\n",
      "        7    0.000    0.000    0.000    0.000 protocol.py:234(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 protocol.py:238(_parse_field_descriptor)\n",
      "      221    0.000    0.000    0.000    0.000 socket.py:730(readable)\n",
      "      221    0.000    0.000    0.000    0.000 {method '_checkClosed' of '_io._IOBase' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'readline' of '_io.BufferedReader' objects}\n",
      "        7    0.000    0.000    0.000    0.000 finalizer.py:45(remove_finalizer)\n",
      "       21    0.000    0.000    0.000    0.000 protocol.py:214(smart_decode)\n",
      "        8    0.000    0.000    0.000    0.000 protocol.py:177(read_struct)\n",
      "        7    0.000    0.000    0.000    0.000 protocol.py:259(description)\n",
      "       14    0.000    0.000    0.000    0.000 __init__.py:1455(debug)\n",
      "        1    0.000    0.000    0.000    0.000 protocol.py:323(__init__)\n",
      "       14    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "        7    0.000    0.000    0.000    0.000 java_gateway.py:973(_get_connection)\n",
      "        1    0.000    0.000    0.000    0.000 connections.py:539(cursor)\n",
      "        2    0.000    0.000    0.000    0.000 cursors.py:97(nextset)\n",
      "        7    0.000    0.000    0.000    0.000 java_gateway.py:988(_give_back_connection)\n",
      "        7    0.000    0.000    0.000    0.000 protocol.py:380(is_fatal_error)\n",
      "       14    0.000    0.000    0.000    0.000 protocol.py:271(get_column_length)\n",
      "        1    0.000    0.000    0.000    0.000 connections.py:1178(__init__)\n",
      "       14    0.000    0.000    0.000    0.000 __init__.py:1724(isEnabledFor)\n",
      "        1    0.000    0.000    0.000    0.000 cursors.py:45(close)\n",
      "        1    0.000    0.000    0.000    0.000 cursors.py:294(fetchall)\n",
      "        2    0.000    0.000    0.000    0.000 cursors.py:83(_nextset)\n",
      "        1    0.000    0.000    0.000    0.000 cursors.py:34(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 cursors.py:336(_do_get_result)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'unpack_from' of '_struct.Struct' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _struct.pack}\n",
      "        5    0.000    0.000    0.000    0.000 cursors.py:65(_get_db)\n",
      "        7    0.000    0.000    0.000    0.000 {method 'pop' of 'collections.deque' objects}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 cursors.py:326(_clear_result)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 cursors.py:110(mogrify)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        1    0.000    0.000    0.000    0.000 cursors.py:70(_check_executed)\n",
      "        1    0.000    0.000    0.000    0.000 protocol.py:183(is_ok_packet)\n",
      "        1    0.000    0.000    0.000    0.000 protocol.py:205(is_load_local_packet)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "\n",
    "def perform_query():\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    results = cursor.fetchall()\n",
    "    cursor.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cProfile.run(\"perform_query()\", sort=\"cumulative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f15c6d",
   "metadata": {},
   "source": [
    "    Total calls: 1,131,181\n",
    "    Total time: 3.526 seconds\n",
    "\n",
    "Top time-consuming functions:\n",
    "\n",
    "    {built-in method builtins.exec}: 3.526 seconds\n",
    "    <string>:1(<module>): 3.526 seconds\n",
    "    3302925674.py:3(perform_query): 3.524 seconds\n",
    "    cursors.py:133(execute): 3.524 seconds\n",
    "    cursors.py:319(_query): 3.524 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee114bb",
   "metadata": {},
   "source": [
    "# Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8215b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"temp_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f96c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_table_sql = \"\"\"\n",
    "# CREATE TABLE ProjectTweets (\n",
    "#     tweet_index INT,\n",
    "#     ids BIGINT,\n",
    "#     date DATE,\n",
    "#     flag STRING,\n",
    "#     user STRING,\n",
    "#     filtered_words_final STRING\n",
    "# )\n",
    "# STORED AS PARQUET\n",
    "# \"\"\"\n",
    "# spark.sql(create_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e014f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hive_insert_data_sql = \"\"\"\n",
    "# INSERT INTO ProjectTweets SELECT * FROM temp_table\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86a95903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(hive_insert_data_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d910743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 22:05:41,602 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-11-05 22:05:41,612 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-11-05 22:05:46,476 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "2023-11-05 22:05:46,476 WARN metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore hduser@127.0.1.1\n",
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+--------+---------------+--------------------+\n",
      "|tweet_index|       ids|      date|    flag|           user|filtered_words_final|\n",
      "+-----------+----------+----------+--------+---------------+--------------------+\n",
      "|          1|1467810672|2009-04-07|NO_QUERY|  scotthamilton|upset,update,face...|\n",
      "|          2|1467810917|2009-04-07|NO_QUERY|       mattycus|kenichan,dived,ma...|\n",
      "|          3|1467811184|2009-04-07|NO_QUERY|        ElleCTF|whole,body,feel,i...|\n",
      "|          4|1467811193|2009-04-07|NO_QUERY|         Karoli|nationwideclass,b...|\n",
      "|          5|1467811372|2009-04-07|NO_QUERY|       joy_wolf| kwesidei,whole,crew|\n",
      "|          6|1467811592|2009-04-07|NO_QUERY|        mybirch|            need,hug|\n",
      "|          7|1467811594|2009-04-07|NO_QUERY|           coZZ|loltrish,hey,long...|\n",
      "|          8|1467811795|2009-04-07|NO_QUERY|2Hood4Hollywood| tatiana,k,nope,didn|\n",
      "|          9|1467812025|2009-04-07|NO_QUERY|        mimismo|  twittera,que,muera|\n",
      "|         10|1467812416|2009-04-07|NO_QUERY| erinx3leannexo|spring,break,plai...|\n",
      "|         11|1467812579|2009-04-07|NO_QUERY|   pardonlauren|      re,pierced,ear|\n",
      "|         12|1467812723|2009-04-07|NO_QUERY|           TLeC|caregiving,couldn...|\n",
      "|         13|1467812771|2009-04-07|NO_QUERY|robrobbierobert|octolinz16,count,...|\n",
      "|         14|1467812784|2009-04-07|NO_QUERY|    bayofwolves|smarrison,ve,firs...|\n",
      "|         15|1467812799|2009-04-07|NO_QUERY|     HairByJess|iamjazzyfizzle,wi...|\n",
      "|         16|1467812964|2009-04-07|NO_QUERY| lovesongwriter|hollis,death,scen...|\n",
      "|         17|1467813137|2009-04-07|NO_QUERY|       armotley|            file,tax|\n",
      "|         18|1467813579|2009-04-07|NO_QUERY|     starkissed|lettya,ahh,ive,al...|\n",
      "|         19|1467813782|2009-04-07|NO_QUERY|      gi_gi_bee|fakerpattypattz,o...|\n",
      "|         20|1467813985|2009-04-07|NO_QUERY|         quanvu|alydesigns,wa,day...|\n",
      "+-----------+----------+----------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Query\n",
    "result = spark.sql(\"SELECT * FROM ProjectTweets\")\n",
    "\n",
    "# Show Result\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "803cd862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YCSB operation completed successfully.\n",
      "Output:\n",
      "/usr/bin/java  -classpath /home/hduser/ycsb-0.17.0/conf:/home/hduser/ycsb-0.17.0/lib/HdrHistogram-2.1.4.jar:/home/hduser/ycsb-0.17.0/lib/core-0.17.0.jar:/home/hduser/ycsb-0.17.0/lib/htrace-core4-4.1.0-incubating.jar:/home/hduser/ycsb-0.17.0/lib/jackson-core-asl-1.9.4.jar:/home/hduser/ycsb-0.17.0/lib/jackson-mapper-asl-1.9.4.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/conf:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/commons-collections-3.2.1.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/commons-lang-2.4.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/commons-pool-1.5.4.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/geronimo-jms_1.1_spec-1.1.1.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/geronimo-jta_1.1_spec-1.1.1.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/jdbc-binding-0.17.0.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/mysql-connector-j-8.0.33.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/mysql-connector-java-8.0.30.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/openjpa-jdbc-2.1.1.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/openjpa-kernel-2.1.1.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/openjpa-lib-2.1.1.jar:/home/hduser/ycsb-0.17.0/jdbc-binding/lib/serp-1.13.1.jar site.ycsb.Client -load -db site.ycsb.db.JdbcDBClient -P /home/hduser/ycsb-0.17.0/jdbc-binding/conf/db.properties -P /home/hduser/ycsb-0.17.0/workloads/workloada -p db.connection_properties=user=root&password=password -p jdbc.url=jdbc:hive2://hive_server:10000/ProjectTweets\n",
      "Adding shard node URL: jdbc:mysql://localhost:3306/ProjectTweets\n",
      "Using shards: 1, batchSize:-1, fetchSize: -1\n",
      "[OVERALL], RunTime(ms), 1205\n",
      "[OVERALL], Throughput(ops/sec), 0.0\n",
      "[TOTAL_GCS_Copy], Count, 0\n",
      "[TOTAL_GC_TIME_Copy], Time(ms), 0\n",
      "[TOTAL_GC_TIME_%_Copy], Time(%), 0.0\n",
      "[TOTAL_GCS_MarkSweepCompact], Count, 0\n",
      "[TOTAL_GC_TIME_MarkSweepCompact], Time(ms), 0\n",
      "[TOTAL_GC_TIME_%_MarkSweepCompact], Time(%), 0.0\n",
      "[TOTAL_GCs], Count, 0\n",
      "[TOTAL_GC_TIME], Time(ms), 0\n",
      "[TOTAL_GC_TIME_%], Time(%), 0.0\n",
      "[CLEANUP], Operations, 1\n",
      "[CLEANUP], AverageLatency(us), 2607.0\n",
      "[CLEANUP], MinLatency(us), 2606\n",
      "[CLEANUP], MaxLatency(us), 2607\n",
      "[CLEANUP], 95thPercentileLatency(us), 2607\n",
      "[CLEANUP], 99thPercentileLatency(us), 2607\n",
      "[INSERT], Operations, 0\n",
      "[INSERT], AverageLatency(us), NaN\n",
      "[INSERT], MinLatency(us), 9223372036854775807\n",
      "[INSERT], MaxLatency(us), 0\n",
      "[INSERT], 95thPercentileLatency(us), 0\n",
      "[INSERT], 99thPercentileLatency(us), 0\n",
      "[INSERT], Return=ERROR, 1\n",
      "[INSERT-FAILED], Operations, 1\n",
      "[INSERT-FAILED], AverageLatency(us), 77088.0\n",
      "[INSERT-FAILED], MinLatency(us), 77056\n",
      "[INSERT-FAILED], MaxLatency(us), 77119\n",
      "[INSERT-FAILED], 95thPercentileLatency(us), 77119\n",
      "[INSERT-FAILED], 99thPercentileLatency(us), 77119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "command = \"/home/hduser/ycsb-0.17.0/bin/ycsb.sh load jdbc -P /home/hduser/ycsb-0.17.0/jdbc-binding/conf/db.properties -P /home/hduser/ycsb-0.17.0/workloads/workloada -p db.connection_properties=\\\"user=root&password=password\\\" -p jdbc.url=jdbc:hive2://hive_server:10000/ProjectTweets\"\n",
    "\n",
    "process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "if process.returncode == 0:\n",
    "    print(\"YCSB operation completed successfully.\")\n",
    "    print(\"Output:\")\n",
    "    print(stdout.decode('utf-8'))\n",
    "else:\n",
    "    print(\"YCSB operation failed. Error message:\")\n",
    "    print(stderr.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ece01872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b0d7be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         4 function calls in 0.000 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 2046835300.py:2(hive_query)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n",
      "         0 function calls in 0.000 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# my_hive_script.py\n",
    "def hive_query():\n",
    "    query\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cProfile.run(\"hive_query()\", sort=\"cumulative\")\n",
    "    \n",
    "    # İşte çıktıyı görüntülemek için pstats modülünü kullanın:\n",
    "    p = pstats.Stats()\n",
    "    p.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327c848c",
   "metadata": {},
   "source": [
    "# SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f8bb242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_sentiment = df.select('date', 'concatenated_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04242ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.window import Window\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8654ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vader SentimentIntensityAnalyzer'ı oluşturun\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# UDF için bir işlev tanımlayın\n",
    "def analyze_sentiment(text):\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    return sentiment['compound']\n",
    "\n",
    "# UDF'yi kaydedin\n",
    "sentiment_udf = udf(analyze_sentiment, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3f16a06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------------+\n",
      "|      date|  concatenated_words|sentiment_score|\n",
      "+----------+--------------------+---------------+\n",
      "|2009-04-07|upset,update,face...|            0.0|\n",
      "|2009-04-07|kenichan,dived,ma...|            0.0|\n",
      "|2009-04-07|whole,body,feel,i...|            0.0|\n",
      "|2009-04-07|nationwideclass,b...|            0.0|\n",
      "|2009-04-07| kwesidei,whole,crew|            0.0|\n",
      "|2009-04-07|            need,hug|            0.0|\n",
      "|2009-04-07|loltrish,hey,long...|            0.0|\n",
      "|2009-04-07| tatiana,k,nope,didn|            0.0|\n",
      "|2009-04-07|  twittera,que,muera|            0.0|\n",
      "|2009-04-07|spring,break,plai...|            0.0|\n",
      "|2009-04-07|      re,pierced,ear|            0.0|\n",
      "|2009-04-07|caregiving,couldn...|            0.0|\n",
      "|2009-04-07|octolinz16,count,...|            0.0|\n",
      "|2009-04-07|smarrison,ve,firs...|            0.0|\n",
      "|2009-04-07|iamjazzyfizzle,wi...|            0.0|\n",
      "|2009-04-07|hollis,death,scen...|            0.0|\n",
      "|2009-04-07|            file,tax|            0.0|\n",
      "|2009-04-07|lettya,ahh,ive,al...|            0.0|\n",
      "|2009-04-07|fakerpattypattz,o...|            0.0|\n",
      "|2009-04-07|alydesigns,wa,day...|            0.0|\n",
      "+----------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Vader analizini uygulayın ve sonuçları yeni bir sütuna ekleyin\n",
    "df_for_sentiment = df_for_sentiment.withColumn(\"sentiment_score\", sentiment_udf(df_for_sentiment[\"concatenated_words\"]))\n",
    "\n",
    "# Sonuçları göstermek için ilk birkaç satırı görüntüleyebilirsiniz\n",
    "df_for_sentiment.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9835e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import avg, col\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import timedelta, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "11e2eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"date\" sütununu 'yyyy-MM-dd' formatına dönüştürün\n",
    "df_for_sentiment = df_for_sentiment.withColumn(\"date\", F.to_date(df_for_sentiment[\"date\"]))\n",
    "\n",
    "# Tarih ve ortalama sentiment puanları için bir veri çerçevesi oluşturun\n",
    "daily_sentiment = df_for_sentiment.groupBy(\"date\").agg(avg(\"sentiment_score\").alias(\"avg_sentiment_score\")).orderBy(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "31902890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:==================================================>   (188 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|      date| avg_sentiment_score|\n",
      "+----------+--------------------+\n",
      "|2009-04-07|-2.22104499274310...|\n",
      "|2009-04-08|                 0.0|\n",
      "|2009-04-09|                 0.0|\n",
      "|2009-04-10|                 0.0|\n",
      "|2009-04-11|                 0.0|\n",
      "|2009-04-12|                 0.0|\n",
      "|2009-04-13|                 0.0|\n",
      "|2009-04-14|                 0.0|\n",
      "|2009-04-15|                 0.0|\n",
      "|2009-04-16|                 0.0|\n",
      "|2009-04-17|                 0.0|\n",
      "|2009-04-18|-2.23096950161170...|\n",
      "|2009-04-19|-1.03626373626373...|\n",
      "|2009-04-20|-7.62942483872716...|\n",
      "|2009-04-21|3.864925709140026E-5|\n",
      "|2009-04-22|                 0.0|\n",
      "|2009-04-23|                 0.0|\n",
      "|2009-04-24|                 0.0|\n",
      "|2009-04-25|                 0.0|\n",
      "|2009-04-26|                 0.0|\n",
      "+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 41:=====================================================>(197 + 1) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Tüm tarih aralığını içerecek şekilde bir tam tarih dizisi oluşturun\n",
    "min_date = daily_sentiment.selectExpr(\"min(date) as min_date\").first().min_date\n",
    "max_date = daily_sentiment.selectExpr(\"max(date) as max_date\").first().max_date\n",
    "\n",
    "# Tarih dizisini oluşturun (tüm günleri içerecek)\n",
    "date_range = [min_date + datetime.timedelta(days=x) for x in range((max_date - min_date).days + 1)]\n",
    "date_range_df = spark.createDataFrame([(date,) for date in date_range], [\"date\"])\n",
    "\n",
    "# Eksik tarihleri doldurun\n",
    "daily_sentiment = date_range_df.join(daily_sentiment, on=[\"date\"], how=\"left\").orderBy(\"date\").fillna(0, subset=[\"avg_sentiment_score\"])\n",
    "\n",
    "# Sonuçları göstermek için ilk birkaç satırı görüntüleyebilirsiniz\n",
    "daily_sentiment.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "36f15bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "import plotly.express as px\n",
    "\n",
    "# Dash uygulamasını başlatın\n",
    "app = dash.Dash(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3c418ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8fba0b7b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uygulamanın düzenini oluşturun\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(\n",
    "        id='sentiment-line-chart',\n",
    "        figure=px.line(daily_sentiment, x='date', y='avg_sentiment_score', title='Daily Average Sentiment Score')\n",
    "    )\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b25fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a88fe34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba1826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff396c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f1cbde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aec0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
